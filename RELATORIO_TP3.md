# TP3: Serverless Computing e Dashboard de Monitoramento

## Relat√≥rio T√©cnico

**Aluno:** T√°ssio Almeida  
**ID:** 2025720437  
**Disciplina:** Cloud Computing - Mestrado UFMG  
**Data:** Dezembro 2025

---

# PARTE I: Task 1 - Fun√ß√£o Serverless

## 1. Introdu√ß√£o

A Task 1 implementa uma fun√ß√£o serverless para processar m√©tricas de recursos do sistema coletadas periodicamente pela VM. A fun√ß√£o calcula indicadores agregados de CPU, mem√≥ria e rede, que s√£o posteriormente visualizados no dashboard da Task 2.

---

## 2. M√©tricas Implementadas

### 2.1 Porcentagem de Tr√°fego de Rede (Egress)

**Descri√ß√£o:** Porcentagem de bytes enviados em rela√ß√£o ao total de tr√°fego

**F√≥rmula:**
```
percent_egress = (bytes_sent / (bytes_sent + bytes_recv)) √ó 100
```

**Implementa√ß√£o:**
```python
bytes_sent = input.get('net_io_counters_eth0-bytes_sent1', 0)
bytes_recv = input.get('net_io_counters_eth0-bytes_recv1', 0)
total_bytes = bytes_sent + bytes_recv

if total_bytes > 0:
    percent_egress = (bytes_sent / total_bytes) * 100.0
else:
    percent_egress = 0.0

results['percent-network-egress'] = round(percent_egress, 2)
```

### 2.2 Porcentagem de Mem√≥ria em Cache

**Descri√ß√£o:** Porcentagem da mem√≥ria total usada para cache (buffers + cached)

**F√≥rmula:**
```
percent_cache = ((cached + buffers) / total) √ó 100
```

**Implementa√ß√£o:**
```python
memory_total = input.get('virtual_memory-total', 1)
memory_cached = input.get('virtual_memory-cached', 0)
memory_buffers = input.get('virtual_memory-buffers', 0)

memory_cache_total = memory_cached + memory_buffers
percent_memory_cache = (memory_cache_total / memory_total) * 100.0

results['percent-memory-cache'] = round(percent_memory_cache, 2)
```

### 2.3 M√©dia M√≥vel de Utiliza√ß√£o de CPU

**Descri√ß√£o:** M√©dia de utiliza√ß√£o de cada CPU nos √∫ltimos 60 segundos

**Janela:** 12 valores (60 segundos √∑ 5 segundos/medi√ß√£o = 12 medi√ß√µes)

**Implementa√ß√£o:** Ver se√ß√£o 3 deste relat√≥rio

---

## 3. Abordagem para Manuten√ß√£o de Estado (M√©dia M√≥vel)

### 3.1 Desafio

A fun√ß√£o serverless √© **stateless** por natureza, mas o c√°lculo de m√©dia m√≥vel requer:
- Hist√≥rico dos √∫ltimos 12 valores de cada CPU
- Persist√™ncia entre execu√ß√µes sucessivas
- Detec√ß√£o din√¢mica do n√∫mero de CPUs do sistema

### 3.2 Solu√ß√£o: Uso de `context.env`

O objeto `context` fornecido pelo runtime serverless possui um campo especial chamado `env` que **persiste entre execu√ß√µes**:

```python
context.env = {}  # Dicion√°rio que mant√©m estado entre chamadas
```

**Por que `context.env`?**

1. **Persiste automaticamente:** O runtime gerencia a persist√™ncia
2. **Sem depend√™ncias externas:** N√£o precisa de Redis ou banco de dados
3. **Acesso r√°pido:** Em mem√≥ria, sem lat√™ncia de rede
4. **Interface padr√£o:** Compat√≠vel com AWS Lambda

### 3.3 Estrutura de Dados

```python
context.env = {
    'cpu_history': {
        '0': [45.5, 43.2, 47.1, 44.8, 46.2, ...],  # √∫ltimos 12 valores
        '1': [32.1, 31.5, 33.0, 30.8, 32.5, ...],
        '2': [67.8, 65.3, 68.9, 66.1, 69.2, ...],
        ...
        '7': [21.4, 22.1, 20.8, 21.9, 22.3, ...]
    }
}
```

### 3.4 Implementa√ß√£o Completa

#### Passo 1: Inicializa√ß√£o do Estado

```python
# Inicializar estado persistente se n√£o existir
if not hasattr(context, 'env'):
    context.env = {}

if 'cpu_history' not in context.env:
    context.env['cpu_history'] = {}
```

#### Passo 2: Identifica√ß√£o Din√¢mica de CPUs

```python
# Identificar todas as CPUs presentes no input
cpu_keys = [key for key in input.keys() if key.startswith('cpu_percent-')]

# Exemplo: ['cpu_percent-0', 'cpu_percent-1', ..., 'cpu_percent-7']
```

#### Passo 3: Processamento e Atualiza√ß√£o do Hist√≥rico

```python
WINDOW_SIZE = 12  # 60 segundos / 5 segundos por medi√ß√£o

for cpu_key in cpu_keys:
    cpu_value = input.get(cpu_key, 0.0)
    
    # Extrair ID da CPU (ex: 'cpu_percent-0' -> '0')
    cpu_id = cpu_key.replace('cpu_percent-', '')
    
    # Inicializar hist√≥rico para esta CPU se n√£o existir
    if cpu_id not in context.env['cpu_history']:
        context.env['cpu_history'][cpu_id] = []
    
    # Adicionar valor atual ao hist√≥rico
    context.env['cpu_history'][cpu_id].append(cpu_value)
    
    # Manter apenas os √∫ltimos WINDOW_SIZE valores (janela deslizante)
    if len(context.env['cpu_history'][cpu_id]) > WINDOW_SIZE:
        context.env['cpu_history'][cpu_id] = \
            context.env['cpu_history'][cpu_id][-WINDOW_SIZE:]
```

#### Passo 4: C√°lculo da M√©dia M√≥vel

```python
    # Obter hist√≥rico atualizado
    cpu_history = context.env['cpu_history'][cpu_id]
    
    # Calcular m√©dia aritm√©tica simples
    avg_cpu_util = sum(cpu_history) / len(cpu_history)
    
    # Adicionar ao resultado
    results[f'avg-util-cpu{cpu_id}-60sec'] = round(avg_cpu_util, 2)
```

### 3.5 Exemplo de Evolu√ß√£o do Estado

**Execu√ß√£o 1:**
```python
Input: cpu0 = 45.5
History: [45.5]
M√©dia: 45.5
```

**Execu√ß√£o 5:**
```python
Input: cpu0 = 44.2
History: [45.5, 47.0, 46.3, 44.8, 44.2]
M√©dia: 45.56
```

**Execu√ß√£o 12:**
```python
Input: cpu0 = 46.8
History: [45.5, 47.0, 46.3, ..., 46.8]  (12 valores)
M√©dia: 46.12
```

**Execu√ß√£o 13 (janela completa):**
```python
Input: cpu0 = 48.1
History: [47.0, 46.3, ..., 46.8, 48.1]  (12 valores - remove o mais antigo)
M√©dia: 46.85
```

### 3.6 Vantagens da Abordagem

| Aspecto | Vantagem |
|---------|----------|
| **Simplicidade** | Sem depend√™ncias externas (DB, Redis adicional) |
| **Performance** | Acesso em mem√≥ria O(1), sem lat√™ncia de rede |
| **Compatibilidade** | Interface padr√£o AWS Lambda |
| **Escalabilidade** | Detecta CPUs dinamicamente |
| **Efici√™ncia** | ~2 KB de mem√≥ria para 8 CPUs |

### 3.7 Limita√ß√µes e Adequa√ß√£o

**Limita√ß√µes:**
- Estado perdido se pod for destru√≠do
- N√£o compartilhado entre m√∫ltiplas r√©plicas
- Limitado a dados pequenos (< 1 MB recomendado)

**Por que √© adequado:**
- ‚úÖ Janela de 60s √© pequena (~96 floats total)
- ‚úÖ Pod √∫nico suficiente para monitoramento
- ‚úÖ Perda de estado recuper√°vel em 60s
- ‚úÖ N√£o requer alta disponibilidade

**Alternativa (se necess√°rio):**
```python
# Para estado dur√°vel, usar Redis:
redis_client.set(f'cpu_history_{cpu_id}', json.dumps(history))
history = json.loads(redis_client.get(f'cpu_history_{cpu_id}'))
```

---

## 4. ConfigMaps Kubernetes

### 4.1 ConfigMap: pyfile

Cont√©m o c√≥digo-fonte completo do m√≥dulo Python:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: pyfile
data:
  pyfile: |
    [c√≥digo completo de handler_module.py]
```

### 4.2 ConfigMap: outputkey

Define a chave Redis para armazenar resultados:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: outputkey
data:
  REDIS_OUTPUT_KEY: "2025720437-proj3-output"
```

---

## 5. Deployment e Resultados

### 5.1 Deploy

```bash
kubectl apply -f configmap-pyfile.yaml
kubectl apply -f configmap-outputkey.yaml
kubectl apply -f serverless-deployment-course.yaml
```

### 5.2 Verifica√ß√£o

```bash
kubectl get pods
# OUTPUT: serverless-redis-6c4d756456-7pqrg   1/1   Running

kubectl logs -f serverless-redis-6c4d756456-7pqrg
# OUTPUT: Environment loaded. Starting execution...
```

### 5.3 Resultado no Redis

**Chave:** `2025720437-proj3-output`

**Dados:**
```json
{
  "percent-network-egress": 0.0,
  "percent-memory-cache": 63.68,
  "avg-util-cpu0-60sec": 100.0,
  "avg-util-cpu1-60sec": 18.69,
  "avg-util-cpu2-60sec": 13.48,
  "avg-util-cpu3-60sec": 13.23,
  "avg-util-cpu4-60sec": 13.99,
  "avg-util-cpu5-60sec": 100.0,
  "avg-util-cpu6-60sec": 13.04,
  "avg-util-cpu7-60sec": 12.24,
  "timestamp": "2025-11-30 15:03:43.211280",
  "num_cpus_monitored": 8
}
```

**An√°lise:**
- 8 CPUs detectadas automaticamente
- CPUs 0 e 5 em alta utiliza√ß√£o (100%)
- Demais CPUs com utiliza√ß√£o normal
- M√©dia m√≥vel calculada corretamente para todas

---

# PARTE II: Task 2 - Dashboard de Monitoramento

## 6. Framework e Tecnologias

### 6.1 Streamlit

**Framework Principal:** Streamlit  
**Vers√£o:** Latest (Python 3.9)

**Justificativa:**
1. **Desenvolvimento R√°pido:** Interface declarativa, sem HTML/CSS
2. **Python Nativo:** Integra√ß√£o direta com redis-py
3. **Componentes Prontos:** Gauges, gr√°ficos, tabelas
4. **Auto-refresh:** Atualiza√ß√£o autom√°tica integrada

### 6.2 Bibliotecas Complementares

- **Plotly:** Gr√°ficos interativos (gauges e barras)
- **Pandas:** Manipula√ß√£o de dados tabulares
- **redis-py:** Conex√£o com Redis

---

## 7. Screenshots do Dashboard

### 7.1 Tela Principal - Vis√£o Geral

**[INSERIR PRINT: Dashboard completo com header, m√©tricas e gauges]**

![Dashboard - Vis√£o Geral](prints/dashboard-overview.png)

**Elementos Vis√≠veis:**
- üìä **Header:** "TP3 - Dashboard de Monitoramento de Recursos"
- üìÖ **Timestamp:** 2025-12-04 22:19:47 (atualizando a cada 5s)
- üíª **CPUs Monitoradas:** 8
- üíæ **Mem√≥ria Usada:** 22.9%
- ‚öôÔ∏è **Configura√ß√µes na Sidebar:**
  - Redis Server: 192.168.121.171:6379
  - Key: 2025720437-proj3-output
  - Auto-refresh: Ativado

---

### 7.2 M√©tricas Gerais

**[INSERIR PRINT: Se√ß√£o de M√©tricas Gerais]**

![M√©tricas Gerais](prints/metricas-gerais.png)

**Visualiza√ß√µes:**

1. **üåê Tr√°fego de Sa√≠da de Rede**
   - Tipo: Barra horizontal azul
   - Valor: 0%
   - An√°lise: Tr√°fego predominantemente de entrada

2. **üíæ Mem√≥ria em Cache**
   - Tipo: Barra horizontal verde
   - Valor: 70.52%
   - An√°lise: Cache: 31.43 GB, Buffers: 1.74 GB

---

### 7.3 Utiliza√ß√£o de CPU (M√©dia M√≥vel 60s)

**[INSERIR PRINT: Grid com 8 gauges de CPU]**

![Gauges de CPU](prints/cpu-gauges.png)

**Descri√ß√£o dos Gauges:**
- **Escala:** 0-100%
- **C√≥digo de Cores:**
  - üü¢ Verde (0-50%): Utiliza√ß√£o normal
  - üü° Amarelo (50-75%): Utiliza√ß√£o m√©dia
  - üî¥ Vermelho (75-100%): Utiliza√ß√£o alta

**Valores Observados:**
- CPU 0: 15.4%
- CPU 1: 11.8%
- CPU 2: 11.1%
- CPU 3: 12.3%
- CPU 4: 100% (alta carga constante)
- CPU 5: 12.3%
- CPU 6: 11.35%
- CPU 7: 64.7%

**An√°lise:**
- CPUs 4 e 7 com cargas elevadas
- Demais CPUs com utiliza√ß√£o baixa/m√©dia
- Distribui√ß√£o desbalanceada (prov√°vel processo pinned)

---

### 7.4 Dados Brutos (M√©tricas de Entrada)

**[INSERIR PRINT: Se√ß√£o expandida "Ver M√©tricas Brutas"]**

![Dados Brutos](prints/dados-brutos.png)

**Conte√∫do:**

**üíª CPU:**
- Tabela com utiliza√ß√£o instant√¢nea de cada CPU
- Valores em porcentagem

**üíæ Mem√≥ria:**
- Total: 47.04 GB
- Usada: 10.54 GB
- Cache: 31.43 GB
- Buffers: 1.74 GB

**üåê Rede:**
- Bytes Enviados: 0.00 MB
- Bytes Recebidos: 0.00 MB

---

### 7.5 JSON Completo (M√©tricas Processadas)

**[INSERIR PRINT: Se√ß√£o expandida "Ver JSON Completo"]**

![JSON Completo](prints/json-completo.png)

**Dados Completos:**
```json
{
  "percent-network-egress": 0,
  "percent-memory-cache": 70.52,
  "avg-util-cpu0-60sec": 16.37,
  "avg-util-cpu1-60sec": 15.54,
  "avg-util-cpu2-60sec": 13.07,
  "avg-util-cpu3-60sec": 12.6,
  "avg-util-cpu4-60sec": 100,
  "avg-util-cpu5-60sec": 14.52,
  "avg-util-cpu6-60sec": 11.35,
  "avg-util-cpu7-60sec": 12.53,
  "timestamp": "2025-12-04 22:23:13.242303",
  "num_cpus_monitored": 8
}
```

---

## 8. Implementa√ß√£o do Dashboard

### 8.1 Conex√£o com Redis

```python
import redis
import json
import os

# Configura√ß√£o via vari√°veis de ambiente
REDIS_HOST = os.getenv('REDIS_HOST', '192.168.121.171')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
REDIS_OUTPUT_KEY = os.getenv('REDIS_OUTPUT_KEY', '2025720437-proj3-output')
REFRESH_INTERVAL = int(os.getenv('REFRESH_INTERVAL', 5))

# Conex√£o com cache
@st.cache_resource
def get_redis_connection():
    r = redis.Redis(
        host=REDIS_HOST,
        port=REDIS_PORT,
        decode_responses=True,
        socket_connect_timeout=5
    )
    r.ping()
    return r

# Busca de m√©tricas
def fetch_metrics(redis_conn):
    data = redis_conn.get(REDIS_OUTPUT_KEY)
    if data:
        return json.loads(data)
    return None
```

**Nota Importante:** O IP `192.168.121.171` √© necess√°rio para acesso de dentro de containers, permitindo que o tr√°fego passe pelo NAT do Docker.

### 8.2 Visualiza√ß√µes Plotly

#### Gauge de CPU

```python
def create_cpu_gauge(cpu_id, value):
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=value,
        title={'text': f"CPU {cpu_id}"},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 50], 'color': "lightgreen"},
                {'range': [50, 75], 'color': "yellow"},
                {'range': [75, 100], 'color': "red"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 90
            }
        }
    ))
    return fig
```

#### Gr√°fico de Barras

```python
def create_percentage_chart(title, value, color):
    fig = go.Figure(go.Bar(
        x=[value],
        y=[title],
        orientation='h',
        marker=dict(color=color),
        text=[f"{value:.2f}%"],
        textposition='inside'
    ))
    fig.update_layout(xaxis=dict(range=[0, 100]))
    return fig
```

### 8.3 Auto-refresh

```python
placeholder = st.empty()

while True:
    with placeholder.container():
        metrics = fetch_metrics(redis_conn)
        
        # Renderizar visualiza√ß√µes
        st.metric("Timestamp", metrics.get('timestamp'))
        # ... outros componentes
    
    if auto_refresh:
        time.sleep(REFRESH_INTERVAL)
    else:
        break
```

---

## 9. Containeriza√ß√£o

### 9.1 Dockerfile

```dockerfile
FROM python:3.9-slim

# Instalar curl para healthcheck
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Depend√™ncias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# C√≥digo
COPY dashboard.py .

EXPOSE 8501

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl --fail http://localhost:8501/_stcore/health || exit 1

# Executar (com file watcher desabilitado)
CMD ["streamlit", "run", "dashboard.py", \
     "--server.port=8501", \
     "--server.address=0.0.0.0", \
     "--server.headless=true", \
     "--server.fileWatcherType=none"]
```

**Observa√ß√£o Cr√≠tica:** O par√¢metro `--server.fileWatcherType=none` √© **essencial** para evitar o erro `inotify instance limit reached` em ambientes Kubernetes.

### 9.2 Depend√™ncias

```
streamlit>=1.28.0
redis>=4.0.0
pandas>=1.5.0
plotly>=5.17.0
```

### 9.3 Build e Push

```bash
# Build na VM (arquitetura AMD64)
docker build -t tassiolucas/tp3-dashboard:v1 .

# Push para Docker Hub
docker login -u tassiolucas
docker push tassiolucas/tp3-dashboard:v1
```

**Imagem Final:**
- Reposit√≥rio: `docker.io/tassiolucas/tp3-dashboard:v1`
- Digest: `sha256:2dcde9fdd89a67509b56dd85d93613922fa829a2bac41e26430931b32a6bf8a4`
- Tamanho: ~450 MB

---

## 10. Deploy no Kubernetes

### 10.1 Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tp3-dashboard
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: dashboard
        image: tassiolucas/tp3-dashboard:v1
        ports:
        - containerPort: 8501
        env:
        - name: REDIS_HOST
          value: "192.168.121.171"
        - name: REDIS_OUTPUT_KEY
          value: "2025720437-proj3-output"
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
```

### 10.2 Service

```yaml
apiVersion: v1
kind: Service
metadata:
  name: tp3-dashboard
spec:
  type: NodePort
  ports:
  - port: 8501
    targetPort: 8501
    nodePort: 30600
  selector:
    app: tp3-dashboard
```

**C√°lculo da Porta:** Porta DevOps (30500) + 100 = **30600**

### 10.3 Status Final

```bash
kubectl get pods
```
```
NAME                             READY   STATUS    RESTARTS   AGE
tp3-dashboard-6f4fd94d45-mtgz5   1/1     Running   0          5m
```

```bash
kubectl get svc tp3-dashboard
```
```
NAME            TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
tp3-dashboard   NodePort   10.43.54.82   <none>        8501:30600/TCP   4d6h
```

---

## 11. Desafios Encontrados e Solu√ß√µes

### 11.1 Incompatibilidade de Arquitetura

**Problema:** Imagem buildada em Mac M1 (ARM64) n√£o funcionava na VM (AMD64)

**Erro:**
```
exec /usr/local/bin/streamlit: exec format error
```

**Tentativas:**
1. `docker build --platform linux/amd64` (n√£o funcionou no Colima)
2. `docker buildx` (n√£o dispon√≠vel no Colima)

**Solu√ß√£o Final:** Build realizado diretamente na VM (AMD64 nativa)

### 11.2 Limite de File Watchers

**Problema:** Streamlit atingindo limite de inotify

**Erro:**
```
OSError: [Errno 24] inotify instance limit reached
```

**Solu√ß√£o:** Desabilitar file watcher via `--server.fileWatcherType=none`

### 11.3 IP do Redis

**Problema Inicial:** Uso de IP incorreto para acesso de containers

**IP Errado:** `192.168.121.48`  
**IP Correto:** `192.168.121.171`

**Explica√ß√£o:** Para acesso de dentro de containers, √© necess√°rio usar o IP da interface p√∫blica da VM (eth0), permitindo que o tr√°fego passe pelo NAT do Docker.

### 11.4 Credenciais Docker Hub

**Problema:** Erro `docker-credential-desktop not found`

**Solu√ß√£o:** 
```bash
echo '{"auths":{}}' > ~/.docker/config.json
docker login -u tassiolucas
```

---

## 12. An√°lise dos Dados Monitorados

### 12.1 Utiliza√ß√£o de CPU

**Observa√ß√µes:**
- **CPU 4:** Constantemente em 100%
- **CPU 7:** Variando entre 60-100%
- **CPUs 0-3, 5-6:** Utiliza√ß√£o baixa (10-20%)

**Interpreta√ß√£o:**
- Processos espec√≠ficos consumindo cores dedicados
- Poss√≠vel process pinning ou workloads espec√≠ficos
- Distribui√ß√£o desbalanceada de carga

### 12.2 Mem√≥ria

**Cache:** 70.52% (~31.43 GB + 1.74 GB)

**An√°lise:**
- Comportamento normal para Linux
- Cache melhora performance de I/O
- Sistema otimizando acesso a disco

### 12.3 Rede

**Tr√°fego de Sa√≠da:** 0%

**An√°lise:**
- VM predominantemente recebendo dados
- Servi√ßos internos (Kubernetes, dashboard)
- Pouco tr√°fego externo

---

## 13. Acesso ao Dashboard

### 13.1 T√∫nel SSH

```bash
ssh -i ~/.ssh/tassioUFMG \
  -L 8501:localhost:30600 \
  tassioalmeida@pugna.snes.2advanced.dev \
  -p 51927
```

### 13.2 Navegador

```
http://localhost:8501
```

### 13.3 Verifica√ß√£o

```bash
# Logs
kubectl logs tp3-dashboard-6f4fd94d45-mtgz5

# Output:
# You can now view your Streamlit app in your browser.
# URL: http://0.0.0.0:8501
```

---

## 14. Conclus√µes

### 14.1 Objetivos Alcan√ßados

**Task 1:**
‚úÖ Fun√ß√£o serverless implementada e deployada  
‚úÖ Tr√™s m√©tricas calculadas corretamente  
‚úÖ M√©dia m√≥vel com estado persistente via `context.env`  
‚úÖ Detec√ß√£o din√¢mica de CPUs  
‚úÖ Integra√ß√£o com Redis funcionando  

**Task 2:**
‚úÖ Dashboard interativo implementado  
‚úÖ Framework Streamlit escolhido e justificado  
‚úÖ Leitura de dados do Redis  
‚úÖ Visualiza√ß√µes com Plotly  
‚úÖ Containeriza√ß√£o e deploy no Kubernetes  
‚úÖ Auto-refresh funcionando  
‚úÖ Acess√≠vel via t√∫nel SSH  

### 14.2 Compet√™ncias Desenvolvidas

1. **Serverless Computing:**
   - Paradigma stateless vs stateful
   - Uso de contexto para estado tempor√°rio
   - Interface AWS Lambda

2. **Visualiza√ß√£o de Dados:**
   - Streamlit para dashboards
   - Plotly para gr√°ficos interativos
   - UX para monitoramento em tempo real

3. **DevOps e Cloud:**
   - Containeriza√ß√£o com Docker
   - Deployment no Kubernetes
   - Troubleshooting de arquitetura
   - ConfigMaps e Services

4. **An√°lise de Performance:**
   - Interpreta√ß√£o de m√©tricas de sistema
   - Identifica√ß√£o de bottlenecks
   - Monitoramento cont√≠nuo

### 14.3 Li√ß√µes Aprendidas

1. **Arquitetura de Containers:**
   - Import√¢ncia de build para arquitetura correta
   - Cross-compilation vs build nativo

2. **Redis em Containers:**
   - Uso de IP correto para NAT do Docker
   - Diferen√ßa entre acesso interno e externo

3. **Streamlit em Produ√ß√£o:**
   - Desabilitar file watchers para evitar limites do sistema
   - Healthchecks para robustez

4. **Estado em Serverless:**
   - `context.env` adequado para janelas pequenas
   - Trade-offs entre simplicidade e durabilidade

### 14.4 Melhorias Futuras

1. **Persist√™ncia de Hist√≥rico:**
   - Armazenar hist√≥rico em TimescaleDB ou InfluxDB
   - Gr√°ficos de tend√™ncia temporal

2. **Alertas Proativos:**
   - Notifica√ß√µes via Slack/Email
   - Thresholds configur√°veis

3. **M√∫ltiplas VMs:**
   - Dashboard agregado
   - Compara√ß√£o entre servidores

4. **Otimiza√ß√µes:**
   - Cache de queries Redis
   - Compress√£o de hist√≥rico

---

## Refer√™ncias

1. AWS Lambda Documentation. Amazon Web Services. Dispon√≠vel em: https://aws.amazon.com/lambda/
2. Kubernetes ConfigMaps. Kubernetes Documentation. Dispon√≠vel em: https://kubernetes.io/docs/concepts/configuration/configmap/
3. Streamlit Documentation. Dispon√≠vel em: https://docs.streamlit.io/
4. Plotly Python Documentation. Dispon√≠vel em: https://plotly.com/python/
5. Redis-py Documentation. Dispon√≠vel em: https://redis-py.readthedocs.io/
6. psutil Documentation. Python Package Index. Dispon√≠vel em: https://psutil.readthedocs.io/

---

## Anexos

### A. Arquivos Entregues

**Task 1:**
- `handler_module.py` - C√≥digo da fun√ß√£o serverless
- `configmap-pyfile.yaml` - ConfigMap com c√≥digo Python
- `configmap-outputkey.yaml` - ConfigMap com chave de sa√≠da

**Task 2:**
- `dashboard.py` - C√≥digo do dashboard
- `Dockerfile` - Container do dashboard
- `requirements.txt` - Depend√™ncias Python
- `dashboard-deployment.yaml` - Deployment Kubernetes
- `dashboard-service.yaml` - Service Kubernetes

### B. Configura√ß√µes do Sistema

**VM:**
- Host: pugna.snes.2advanced.dev
- Porta SSH: 51927
- Usu√°rio: tassioalmeida

**Redis:**
- Host: 192.168.121.171
- Porta: 6379
- Chave Input: `metrics`
- Chave Output: `2025720437-proj3-output`

**Kubernetes:**
- Namespace: tassioalmeida
- Dashboard NodePort: 30600

### C. Reposit√≥rio Docker Hub

- **Task 2:** `tassiolucas/tp3-dashboard:v1`

---

**Fim do Relat√≥rio**

